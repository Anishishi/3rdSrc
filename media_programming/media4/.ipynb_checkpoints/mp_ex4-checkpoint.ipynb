{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第4回課題：夏目漱石の「吾輩は猫である」っぽい文を生成してみよう！\n",
    "\n",
    "**課題は結果が出力されている状態で保存して提出してください！**\n",
    "\n",
    "## 課題１：分かち書き文の生成\n",
    "\n",
    "`text/wagahaiwa_nekodearu_org.txt`には、夏目漱石の小説「吾輩は猫である」の本文が記録されています。   \n",
    "このテキストを半角スペース区切りの分かち書き文に変換して、`text/wagahaiwa_nekodearu_wakati.txt`に保存してください。  \n",
    "なお、改行は削除せずにそのまま残してしておいてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from janome.tokenizer import Tokenizer\n",
    "\n",
    "t = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'text/wagahaiwa_nekodearu_org.txt'\n",
    "\n",
    "words = [t.tokenize(l, wakati=True) for l in open(file, 'r', encoding='utf-8').readlines()]\n",
    "texts=[]\n",
    "for i in words:\n",
    "    texts.append(' '.join(i)+'\\n')\n",
    "with open('text/wagahaiwa_nekodearu_wakati.txt', 'w') as fw:\n",
    "    fw.writelines(texts)\n",
    "fw.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "冒頭の1文を出力してください。  \n",
    "次のような文が出てきたら正解です。  \n",
    "```吾輩 は 猫 で ある 。 名前 は まだ 無い 。 ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "吾輩 は 猫 で ある 。 名前 は まだ 無い 。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題２：ランダム文生成\n",
    "\n",
    "下のセルで、課題１で作成した`text/wagahaiwa_nekodearu_wakati.txt`を入力として、統計的tri-gramモデルを学習してください。  \n",
    "学習モデルの変数名は`lm`とします。   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm import Vocabulary\n",
    "from nltk.lm.models import MLE\n",
    "from nltk.util import ngrams\n",
    "\n",
    "train_file = 'text/wagahaiwa_nekodearu_wakati.txt'\n",
    "\n",
    "words_train = [('<BOP> ' + l + ' <EOP>').split() for l in open(train_file, 'r', encoding='utf-8').readlines()]\n",
    "\n",
    "vocab = Vocabulary([item for sublist in words_train for item in sublist])\n",
    "text_trigrams = [ngrams(word_t, 3) for word_t in words_train] \n",
    "\n",
    "n = 3\n",
    "lm = MLE(order = n, vocabulary = vocab) # 最尤推定法（Maximum Likelihood Estimation)による統計的n-gram言語モデルの準備\n",
    "lm.fit(text_trigrams) # 上で生成したtri-gramを使って言語モデルを学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習したモデル`lm`を使って、以下のセルで「吾輩は」から始まる文を10文生成してください。   \n",
    "生成文は「吾輩は」から始めて、`。`あるいは`」`で終わる一文を基本としますが、より自然な文となるよう、独自の改良を加えても構いません。   \n",
    "**生成文が出力されている状態で保存して提出してください。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "吾輩は仕方がない。\n",
      "吾輩は猫である。\n",
      "吾輩は実を云う。\n",
      "吾輩は息を入れる。\n",
      "吾輩は再び下女を顧みる。\n",
      "吾輩は猫であろう。\n",
      "吾輩はこの事だ。\n",
      "吾輩は鑑定をつけている。\n",
      "吾輩は前足の助けを借りて詐偽を働らく。\n",
      "吾輩は突然細君に話しかける。\n"
     ]
    }
   ],
   "source": [
    "##50通りの'。'または'」'で終わる文をランダムに作成し、それらのうち宮沢賢治らしい10通りの文を抽出して解答とした。\n",
    "\n",
    "\n",
    "ans=[]\n",
    "for cnt in range(50):\n",
    "    context = ['吾輩', 'は']\n",
    "    for i in range(0, 100):\n",
    "        # contextのうち最後の2単語から次に繋がる確率0じゃない単語をランダムに選ぶ\n",
    "        w = lm.generate(text_seed=context)\n",
    "        context.append(w) # 選ばれた単語をcontextに連結\n",
    "        if '。' == w or '<EOP>' == w or '」'==w: # 句点「。」か<EOP>に到達したらそこで終了\n",
    "            break\n",
    "    ans.append(context)\n",
    "### 100通りの入力文からどの10通りの文が宮沢賢治らしいかを導く###\n",
    "p_dic={}\n",
    "for i in range(len(ans)):\n",
    "    n = 3 # lm (言語モデル) はtri-gramで学習しているので、ここではn=3を指定\n",
    "    probability = 1.0 # 始め確率は1.0に初期化\n",
    "    for ngram in ngrams(ans[i], n):\n",
    "        # 2単語の後に3単語目が続く確率をひたすら計算\n",
    "        prob = lm.score(lm.vocab.lookup(ngram[-1]),\n",
    "                        lm.vocab.lookup(ngram[:-1]))\n",
    "        # 確率が0にならないように微小な値をprobに代入する\n",
    "        prob = max(prob, 1e-8)\n",
    "        # tri-gramの生起確率をかけ合わせていく\n",
    "        probability *= prob\n",
    "    p_dic[probability]=i\n",
    "    #print(probability)\n",
    "p_dicsorted=sorted(p_dic.items(), reverse=True)\n",
    "#それら10通りを表示する\n",
    "for i in range(10):\n",
    "    print(''.join(ans[p_dicsorted[i][1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "たとえば次のような文が生成されます（これは一例です）。\n",
    "```\n",
    "吾輩は文明の咒詛だ。\n",
    "吾輩はにゃあにゃあと甘えるごとく、雲を行くがごとく腹内に誘致する職務を帯びている。\n",
    "吾輩はちょっとむっとする。\n",
    "吾輩は無論しやせずして来た。\n",
    "吾輩はやはり地面の上を摩擦した女で、気の利かぬ主人は一人が「へえアンドレア・デル・サルトが言ったがそれぎれで手掛りがないから、おとなしく独乙皇帝陛下のように述べ立てる。\n",
    "吾輩は謹んで拝見すると云わぬばかりの顔も遠慮なく見るし、Ｔ１Ｔ2……。\n",
    "吾輩は少からざる尊敬をもって反覆読誦したのね。\n",
    "吾輩は年来美学上の利害もないんです。\n",
    "吾輩はこの近辺でやられて、近火の手でさあ。\n",
    "吾輩は波を打った。\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
